{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal for Group 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Alex Park\n",
    "- Sandra Lin\n",
    "- Derrick Lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured\n",
    "\n",
    "Optimized Scheduling and Resource Allocation\n",
    "Techniques Used:\n",
    "Genetic Algorithms and Simulated Annealing: For finding optimal scheduling solutions that balance multiple constraints and objectives.\n",
    "Markov Decision Processes (MDPs): To model decision-making processes in an environment with uncertain outcomes.\n",
    "Dynamic Programming: For efficient computation of optimal policies in resource allocation.\n",
    "Course Relevance: Incorporates uncertainty and partial observability in practical applications, applying complex algorithms to derive efficient solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "<!--You should have a strong idea of what dataset(s) will be used to accomplish this project. \n",
    "\n",
    "If you know what (some) of the data you will use, please give the following information for each dataset:\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc will be needed\n",
    "\n",
    "If you don't yet know what your dataset(s) will be, you should describe what you desire in terms of the above bullets.-->\n",
    "\n",
    "For our project, we will be using the Breast Cancer Wisconsin (Original) dataset, available from the UCI Machine Learning Repository. This dataset is a classic in medical data analysis, particularly for machine learning applications aimed at understanding cancer classification based on various diagnostic measurements.\n",
    "\n",
    "### Dataset Characteristics\n",
    "- **Source**: [Breast Cancer Wisconsin (Original) - UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original))\n",
    "- **Number of Instances**: 699\n",
    "- **Number of Features**: 9, plus the class attribute\n",
    "- **Missing Values**: Yes, specifically in the 'Bare Nuclei' feature\n",
    "\n",
    "### Description of Data\n",
    "The dataset comprises measurements from digitized images of fine needle aspirate (FNA) of breast mass. Each instance corresponds to an image, with the following attributes (excluding the ID number which we will disregard for analysis):\n",
    "1. **Clump Thickness**: Integer (1-10)\n",
    "2. **Uniformity of Cell Size**: Integer (1-10)\n",
    "3. **Uniformity of Cell Shape**: Integer (1-10)\n",
    "4. **Marginal Adhesion**: Integer (1-10)\n",
    "5. **Single Epithelial Cell Size**: Integer (1-10)\n",
    "6. **Bare Nuclei**: Integer (1-10), contains missing values\n",
    "7. **Bland Chromatin**: Integer (1-10)\n",
    "8. **Normal Nucleoli**: Integer (1-10)\n",
    "9. **Mitoses**: Integer (1-10)\n",
    "\n",
    "### Class Labels\n",
    "- **Benign**: Encoded as 2\n",
    "- **Malignant**: Encoded as 4\n",
    "\n",
    "### Critical Variables\n",
    "- **Bare Nuclei**: This feature contains missing values and will require imputation. Given its clinical significance in cancer diagnosis, how we handle its missing data could significantly influence model performance.\n",
    "- **Clump Thickness** and **Uniformity of Cell Size**: These features are particularly noteworthy as they can indicate the severity of cancerous formations.\n",
    "\n",
    "### Data Handling\n",
    "Due to the presence of missing values in the 'Bare Nuclei' feature, we will need to perform data cleaning. Options include imputation using statistical methods or more complex machine learning models. Additionally, given the range and nature of the features, standardizing or normalizing the data might be necessary to improve algorithm performance.\n",
    "\n",
    "This dataset, with its rich feature set and real-world applicability, offers a robust platform for developing and testing machine learning models aimed at classifying cancerous conditions, thus potentially improving diagnostic processes in medical practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "<!--In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. -->\n",
    "\n",
    "The primary goal is to accurately predict the malignancy of breast cancer samples based on several cell features. Below are the key components and methodologies of our proposed solution:\n",
    "\n",
    "1. **Machine Learning Models**: We will employ various machine learning models including Support Vector Machines, Random Forests, and Neural Networks. These models are chosen due to their proven effectiveness in handling binary classification tasks like cancer diagnosis.\n",
    "\n",
    "2. **Feature Engineering and Selection**:\n",
    "   - **Handling Missing Data**: We will address missing values in the 'Bare Nuclei' feature using predictive modeling, possibly employing a simpler classifier to impute these values.\n",
    "   - **Feature Selection Techniques**: To identify the most predictive features, we will use Recursive Feature Elimination (RFE) and feature importance scores from ensemble methods like Random Forests.\n",
    "\n",
    "3. **Optimization Algorithms**:\n",
    "   - **Genetic Algorithms (GA)**: Inspired by evolutionary biology, GA will be used for feature selection to optimize the subset of features that results in the best predictive performance.\n",
    "   - **Simulated Annealing**: This technique will be explored to optimize hyperparameters of the chosen models, enhancing the model's ability to generalize to unseen data.\n",
    "\n",
    "4. **Reinforcement Learning (RL)**:\n",
    "   - While RL is typically not used in static classification tasks, we propose a novel approach by treating the feature selection process as an episodic reinforcement learning problem, where the agent's actions involve selecting or excluding features, and rewards are based on model accuracy and complexity.\n",
    "\n",
    "5. **Evaluation Strategy**:\n",
    "   - We will continuously evaluate the models during the training process using a validation set, and finally on a separated test set to ensure that our models generalize well beyond the training data.\n",
    "\n",
    "By integrating these sophisticated AI and machine learning techniques, our project aims not only to achieve high accuracy in breast cancer diagnosis but also to push forward the methodological boundaries by exploring how strategies from different subfields of AI can enhance traditional predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "<!--Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).-->\n",
    "\n",
    "To robustly evaluate the performance of our machine learning models on the Breast Cancer Wisconsin (Original) dataset, we propose using the following metrics specifically chosen to capture both the accuracy and reliability of the diagnostic predictions:\n",
    "\n",
    "1. **Accuracy**: This is a straightforward indicator of how often the model correctly identifies cancer status. It provides the proportion of total correct predictions (both benign and malignant) out of all predictions made.\n",
    "\n",
    "2. **Confusion Matrix-derived Metrics**:\n",
    "   - **Precision**: Measures the proportion of positive identifications that were actually correct, crucial for minimizing false alarms in medical diagnostics.\n",
    "   - **Recall** (Sensitivity): Measures the proportion of actual positives that were correctly identified, essential for detecting as many true cases of cancer as possible.\n",
    "   - **F1 Score**: The harmonic mean of precision and recall, providing a balance between the two in cases of class imbalance.\n",
    "\n",
    "3. **ROC-AUC Score**: This metric will help understand the trade-offs between true positive rate and false positive rate, which is crucial for medical diagnostics where the consequences of both types of errors are significant. The Area Under the Curve (AUC) provides a single measure of overall model performance across all classification thresholds.\n",
    "\n",
    "These metrics will be computed using a cross-validated approach to ensure robustness against overfitting and provide a realistic estimation of the model’s performance on unseen data. This comprehensive evaluation strategy will allow us to compare the performance of different models and configurations accurately, ensuring the selection of the best model and settings for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ***Data Privacy:*** Since we are using the sensitive medical data, we must ensure the privacy and confidentiality of patient information. We must obey to all relevant data protection regulations, such as HIPAA (Health Insurance Portability and Accountability Act) in the United States, and obtain proper consent for data usage and sharing that UCI Machine Learning Repository has which is that we can browse our site or download datasets without providing any personal information such as your name, mailing address, email address, phone number, or social security number.\n",
    "\n",
    "\n",
    "2. ***Bias and Fairness:*** We acknowledge the potential for bias in healthcare data, influenced by factors such as demographics, socioeconomic status, and access to healthcare. Our team will evaluate our machine learning model for any biases in the dataset or introduced by the algorithms used. We will implement strategies to mitigate bias and ensure fairness in our predictions, striving to avoid favoring or disadvantaging any specific demographic group or individual. Additionally, we will actively monitor model performance across different subgroups to identify and address any disparities in predictive accuracy.\n",
    "\n",
    "\n",
    "3. ***Informed Consent:*** Given that the Breast Cancer Wisconsin dataset sourced from the UCI Machine Learning Repository is publicly available and anonymized, individual contributors' explicit consent may not be applicable. However, we remain committed to upholding ethical standards by ensuring transparency regarding the dataset's origin and usage within our project. We will provide clear communication about the dataset's purpose and how it will be utilized for research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Team Expectation 1:*** Each team member will actively contribute to the research, data preprocessing, feature engineering, model development, optimization, evaluation, and reporting phases of the project.\n",
    "\n",
    "***Team Expectation 2:*** Maintain regular and open communication channels within the team through IMessage, discussing progress, challenges, and ideas respectfully.\n",
    "\n",
    "***Team Expectation 3:*** Meeting project milestones and deadlines, with shared responsibility for different aspects of the project, and make sure that we follow up with each other.\n",
    "\n",
    "***Team Expectation 4:*** Aim to attend all scheduled meetings, with allowances for one to two absences per team member throughout the project if they need it. \n",
    "\n",
    "***Team Expectation 5:*** When conflicts or disagreements arise, openly acknowledge and discuss them within the team so, everyone is comfortable sharing their thoughts and making a good decision.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 5/1  |  8 PM |  Read & Think about COGS 188 expectations; brainstorm topics/questions  | Finalize methodology: Plan to use available datasets on specific ML methods such as Breast Cancer Wisconsin; Arrange the contributions of each individual within the team.| \n",
    "| 5/3  |  8 PM |  Clean data: potential missing values, focusing on the 'Bare Nuclei' feature, and ensure data consistency. | Discuss ideal datasets and ethics; submit project proposal | \n",
    "| 5/10  | 8 PM  | Utilize techniques like Recursive Feature Elimination (RFE) for feature selection. | Train various machine learning models including Support Vector Machines, Random Forests, and Neural Networks.|\n",
    "| 5/17   |  8 PM | Optimize model hyperparameters using Genetic Algorithms and Simulated Annealing. | Prepare report: Compile findings, methodology, and conclusions into a succinct report. |\n",
    "| 5/24  |  8 PM | Review/Edit; Discuss Analysis Plan | Discuss/edit project code |\n",
    "| 5/31  |  8 PM | Complete analysis; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 6/12  | Before 10 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"uci-note\"></a>1.[^](#uci): Wolberg, W. (14 Jul 1992). Breast Cancer Wisconsin (Original). UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)<br>\n",
    "\n",
    "<a name=\"Kim, Dong Wook\"></a>2.[^](#Kim): Kim, Dong Wook, et al. (6 May 2019) “Deep Learning-Based Survival Prediction of Oral Cancer Patients.” *Nature News*, Nature Publishing Group, https://www.nature.com/articles/s41598-019-43372-7<br> \n",
    "\n",
    "<a name=\"Esteva, Andre\"></a>3.[^](#Esteva): Esteva, Andre, et al. (25 Jan 2017) \"Dermatologist-Level Classification of Skin Cancer with Deep Neural Networks.\" *Nature News*, Nature Publishing Group, https://www.nature.com/articles/nature21056.<br> \n",
    "\n",
    "<a name=\"Ebtisam, Hamed\"></a>4.[^](#Ebtisam): Ebtisam, Hamed, et al. (21 June 2018) An Analysis of Particle Swarm Optimization for Feature Selection on Medical Data | IEEE Conference Publication | *IEEE Xplore*, IEEE, https://ieeexplore.ieee.org/document/8389840. <br> \n",
    "\n",
    "<a name=\"Amazona, Adorada\"></a>5.[^](#Amazona): Amazona, Adorada, et al. (24 Jan 2019). Support Vector Machine - Recursive Feature Elimination (SVM - RFE) for Selection of MicroRNA Expression Features of Breast Cancer, https://ieeexplore.ieee.org/abstract/document/8621708 <br> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
